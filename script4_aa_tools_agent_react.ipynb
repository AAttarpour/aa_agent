{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d86963ea",
   "metadata": {},
   "source": [
    "- This code has written by Ahmadreza Attarpour (a.attarpour@mail.utoronto.ca)\n",
    "- It's a practice to check how we can use LangChain/LangGraph to build tools and agents\n",
    "\n",
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb35a012",
   "metadata": {},
   "source": [
    "# ReAct Agent\n",
    "\n",
    "- Loop of observation, action and thought\n",
    "- The agent uses a combination reasoning steps to guide actions in real-time, using feedback from those actions to further inform the next step in reasoning\n",
    "\n",
    "\n",
    "Prompt --> reasoning --> actions --> observation and reasoning --> repeat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a19adb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ba50a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the environment variables from the .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03cd57a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the variable from the environment and set it as a env variable\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "LANGCHAIN_PROJECT = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "if GOOGLE_API_KEY:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "if LANGCHAIN_API_KEY:\n",
    "    os.environ[\"LANGCHAIN_API_KEY\"] = LANGCHAIN_API_KEY\n",
    "if LANGCHAIN_PROJECT:\n",
    "    os.environ[\"LANGCHAIN_PROJECT\"] = LANGCHAIN_PROJECT\n",
    "if os.getenv(\"TAVILY_API_KEY\"):\n",
    "    os.environ[\"TAVILY_API_KEY\"] = os.getenv(\"TAVILY_API_KEY\")\n",
    "if os.getenv(\"GROQ_API_KEY\"):\n",
    "    os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "if os.getenv(\"SERPER_API_KEY\"):\n",
    "    os.environ[\"SERPER_API_KEY\"] = os.getenv(\"SERPER_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c91e0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the LLM and embeddings from langchain_google_genai\n",
    "# from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "# embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "# from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "# llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2055f0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ahmadreza/anaconda3/envs/aa_agent/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "# This is a sentence-transformers model: It maps sentences & paragraphs to a\n",
    "# 384 dimensional dense vector space and can be used for tasks like clustering or semantic search.\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(model=\"Gemma2-9b-It\")\n",
    "# llm = ChatGroq(model=\"llama3-70b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e89eb355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(model_name='all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, query_encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9773a03d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of Iran is **Tehran**. \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 16, 'total_tokens': 29, 'completion_time': 0.023636364, 'prompt_time': 0.001245901, 'queue_time': 0.102435938, 'total_time': 0.024882265}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--c3f26dac-8d15-4b76-80ce-2953618e4631-0', usage_metadata={'input_tokens': 16, 'output_tokens': 13, 'total_tokens': 29})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What is the capital of Iran?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aae63bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utilities import GoogleSerperAPIWrapper\n",
    "from langchain.agents import Tool\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.agents import create_react_agent, AgentExecutor, tool\n",
    "from langchain import hub\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cd4dfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the search tool\n",
    "search = GoogleSerperAPIWrapper()\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"GoogleSearch\",\n",
    "        func=search.run,\n",
    "        description=\"Useful for when you need to answer questions with search.\",\n",
    "        verbose=True\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40f7c909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the prompt template\n",
    "template = '''Answer the following questions as best you can. You have access to the following tools:\n",
    "{tools}\n",
    "Use the following format:\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Observation Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "Begin!\n",
    "Question: {input}\n",
    "Thought: {agent_scratchpad}'''\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc49b25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the agent\n",
    "agent = create_react_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f46ba8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools, \n",
    "    verbose=True,\n",
    "    return_intermediate_steps=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3aaaa9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: This question requires knowledge about image analysis techniques specifically for light sheet microscopy data of cFos expression. I need to research common segmentation and analysis methods used for this type of data.\n",
      "\n",
      "Action: GoogleSearch\n",
      "Action Input: \"light sheet microscopy cFos segmentation analysis\"\u001b[0m\u001b[36;1m\u001b[1;3mAdvances in microscopy, such as light-sheet fluorescence microscopy ... segmentation maps are passed to the cluster-wise analysis module ... This work presents a valuable self-supervised method for the segmentation of 3D cells in microscopy images, alongside an implementation as a Napari plugin ... Light-sheet microscopy (LSM) has proven a useful tool in neuroscience to image whole brains with high frame rates at cellular resolution and, in combination ... We generated high-quality annotations of light-sheet microscopy data of cleared whole mouse brains stained for c-Fos in a VR environment. Next, ... We reasoned that volume imaging using light sheet fluorescence microscopy (LSFM) coupled with tissue clearing could be a powerful alternative to STP for imaging ... In this study, we started with utilizing a combination of TLSM and CUBIC-L to visualize the MNs of ChAT-eGFP mice during postnatal development. Missing: cFos | Show results with:cFos. In this study, we propose NEATmap, a deep learning–based high-efficiency segmentation and analysis pipeline for whole-brain neuronal activity trace mapping. Our ... Full Length Article. 3D imaging and pathological analysis of microglia in LPS-treated mice with light-sheet fluorescence microscopy. Missing: cFos | Show results with:cFos. We reasoned that volume imaging using light sheet fluorescence microscopy (LSFM) coupled with tissue clearing could be a powerful ... Segmentation, a crucial preliminary step in the analysis process, can be automated using domain-specific deep learning models with expert ...\u001b[0m\u001b[32;1m\u001b[1;3mThought: Based on the search results, it seems like deep learning models are gaining traction for segmenting cFos expression in light sheet microscopy data.  I should look into specific models and pipelines mentioned.\n",
      "\n",
      "Action: GoogleSearch\n",
      "Action Input: \"NEATmap cFos segmentation\"\u001b[0m\u001b[36;1m\u001b[1;3mNEATmap enables more accurate 3D segmentation of c-Fos+ (Fig. 2i and j) by automated inferencing of the dual-channel whole-brain imaging dataset in about 40 ... Here, we introduce NEATmap, a deep learning-based high-efficiency, high-precision and user-friendly software for whole-brain neuronal activity ... NEATmap is a deep learning software for whole-brain neuronal activity mapping, using automated segmentation and quantitative analysis of c-Fos neurons. Our open-source pipeline enables whole-brain mapping of neuronal ensembles at a high level of precision across a wide range of neuroscientific applications. This open-source and user-friendly tool will facilitate the atlas registration of diverse tissue types, unconventional atlas organizations, and a variety of ... ClearMap is an automated platform using tissue clearing and activity mapping, profiling immediate early gene expression to map brain activity. Expression of IEGs such as c-fos are frequently used as a proxy of neural activity. For instance, recent studies have used tissue clearing, IEG- ... Tutorial for editing and using ClearMap2's CellMap script for activity mapping of cFos ... Deep Learning Image Restoration and Segmentation ... The c-Fos averaged density maps (n = 6 per group, except parenting females n = 3) show the increased activity in the rostral part of the ... The segmentation maps are based on CNN predictions. Green: NeuN, magenta: cFOS. Scale bar: 200 µm. Source publication.\u001b[0m\u001b[32;1m\u001b[1;3mThought: It seems NEATmap is a promising tool specifically designed for cFos segmentation in light sheet microscopy data. \n",
      "\n",
      "Final Answer:  A good starting point for segmenting and analyzing your cFos light sheet data would be to explore the NEATmap software. It's a deep learning-based pipeline designed for this specific purpose and offers high-precision segmentation of cFos neurons in whole-brain imaging.  \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"I have huge light sheet data of cFos, what's the best way to segment and analyze it?\",\n",
       " 'output': \"A good starting point for segmenting and analyzing your cFos light sheet data would be to explore the NEATmap software. It's a deep learning-based pipeline designed for this specific purpose and offers high-precision segmentation of cFos neurons in whole-brain imaging.\",\n",
       " 'intermediate_steps': [(AgentAction(tool='GoogleSearch', tool_input='light sheet microscopy cFos segmentation analysis', log='Thought: This question requires knowledge about image analysis techniques specifically for light sheet microscopy data of cFos expression. I need to research common segmentation and analysis methods used for this type of data.\\n\\nAction: GoogleSearch\\nAction Input: \"light sheet microscopy cFos segmentation analysis\"'),\n",
       "   'Advances in microscopy, such as light-sheet fluorescence microscopy ... segmentation maps are passed to the cluster-wise analysis module ... This work presents a valuable self-supervised method for the segmentation of 3D cells in microscopy images, alongside an implementation as a Napari plugin ... Light-sheet microscopy (LSM) has proven a useful tool in neuroscience to image whole brains with high frame rates at cellular resolution and, in combination ... We generated high-quality annotations of light-sheet microscopy data of cleared whole mouse brains stained for c-Fos in a VR environment. Next, ... We reasoned that volume imaging using light sheet fluorescence microscopy (LSFM) coupled with tissue clearing could be a powerful alternative to STP for imaging ... In this study, we started with utilizing a combination of TLSM and CUBIC-L to visualize the MNs of ChAT-eGFP mice during postnatal development. Missing: cFos | Show results with:cFos. In this study, we propose NEATmap, a deep learning–based high-efficiency segmentation and analysis pipeline for whole-brain neuronal activity trace mapping. Our ... Full Length Article. 3D imaging and pathological analysis of microglia in LPS-treated mice with light-sheet fluorescence microscopy. Missing: cFos | Show results with:cFos. We reasoned that volume imaging using light sheet fluorescence microscopy (LSFM) coupled with tissue clearing could be a powerful ... Segmentation, a crucial preliminary step in the analysis process, can be automated using domain-specific deep learning models with expert ...'),\n",
       "  (AgentAction(tool='GoogleSearch', tool_input='NEATmap cFos segmentation', log='Thought: Based on the search results, it seems like deep learning models are gaining traction for segmenting cFos expression in light sheet microscopy data.  I should look into specific models and pipelines mentioned.\\n\\nAction: GoogleSearch\\nAction Input: \"NEATmap cFos segmentation\"'),\n",
       "   \"NEATmap enables more accurate 3D segmentation of c-Fos+ (Fig. 2i and j) by automated inferencing of the dual-channel whole-brain imaging dataset in about 40 ... Here, we introduce NEATmap, a deep learning-based high-efficiency, high-precision and user-friendly software for whole-brain neuronal activity ... NEATmap is a deep learning software for whole-brain neuronal activity mapping, using automated segmentation and quantitative analysis of c-Fos neurons. Our open-source pipeline enables whole-brain mapping of neuronal ensembles at a high level of precision across a wide range of neuroscientific applications. This open-source and user-friendly tool will facilitate the atlas registration of diverse tissue types, unconventional atlas organizations, and a variety of ... ClearMap is an automated platform using tissue clearing and activity mapping, profiling immediate early gene expression to map brain activity. Expression of IEGs such as c-fos are frequently used as a proxy of neural activity. For instance, recent studies have used tissue clearing, IEG- ... Tutorial for editing and using ClearMap2's CellMap script for activity mapping of cFos ... Deep Learning Image Restoration and Segmentation ... The c-Fos averaged density maps (n = 6 per group, except parenting females n = 3) show the increased activity in the rostral part of the ... The segmentation maps are based on CNN predictions. Green: NeuN, magenta: cFOS. Scale bar: 200 µm. Source publication.\")]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\n",
    "    \"input\": \"I have huge light sheet data of cFos, what's the best way to segment and analyze it?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e8e793",
   "metadata": {},
   "source": [
    "# custom tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38076e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom tool\n",
    "@tool\n",
    "def get_employee_id(name: str) -> str:\n",
    "    \"\"\"Get the employee ID for a given name.\"\"\"\n",
    "\n",
    "    fake_employees = {\n",
    "        \"Alice\": \"12345\",\n",
    "        \"Bob\": \"67890\",\n",
    "        \"Charlie\": \"54321\",\n",
    "        \"David\": \"98765\",\n",
    "        \"Eve\": \"11223\",\n",
    "        \"Frank\": \"44556\",\n",
    "        \"Grace\": \"77889\",\n",
    "        \"Heidi\": \"33445\",\n",
    "        \"Ivan\": \"66778\",\n",
    "        \"Judy\": \"88990\"\n",
    "    }\n",
    "    # This is a mock implementation, replace with actual logic\n",
    "    return fake_employees.get(name, \"Employee not found\")\n",
    "\n",
    "@tool\n",
    "def get_employee_salary(name: str) -> str:\n",
    "    \"\"\"Get the employee salary for a given name.\"\"\"\n",
    "\n",
    "    fake_salaries = {\n",
    "        \"Alice\": \"$100,000\",\n",
    "        \"Bob\": \"$120,000\",\n",
    "        \"Charlie\": \"$110,000\",\n",
    "        \"David\": \"$130,000\",\n",
    "        \"Eve\": \"$140,000\",\n",
    "        \"Frank\": \"$150,000\",\n",
    "        \"Grace\": \"$160,000\",\n",
    "        \"Heidi\": \"$170,000\",\n",
    "        \"Ivan\": \"$180,000\",\n",
    "        \"Judy\": \"$190,000\"\n",
    "    }\n",
    "    # This is a mock implementation, replace with actual logic\n",
    "    return fake_salaries.get(name, \"Salary not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25f393d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the tools\n",
    "tools = [\n",
    "    get_employee_id,\n",
    "    get_employee_salary\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "957053b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "{tools}\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [{tool_names}]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: {input}\n",
      "Thought:{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "# get the prompt\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "print(prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f2fcedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the agent\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools, \n",
    "    verbose=True,\n",
    "    return_intermediate_steps=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e42e4145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find Alice's employee ID first and then use it to get her salary.\n",
      "Action: get_employee_id\n",
      "Action Input: Alice\u001b[0m\u001b[36;1m\u001b[1;3m12345\u001b[0m\u001b[32;1m\u001b[1;3mThought: Now that I have Alice's employee ID, I can get her salary.\n",
      "Action: get_employee_salary\n",
      "Action Input: Alice\u001b[0m\u001b[33;1m\u001b[1;3m$100,000\u001b[0m\u001b[32;1m\u001b[1;3mThought: I now know the final answer\n",
      "Final Answer: Alice's salary is $100,000 \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"what's the salary of Alice?\",\n",
       " 'output': \"Alice's salary is $100,000\",\n",
       " 'intermediate_steps': [(AgentAction(tool='get_employee_id', tool_input='Alice', log=\"Thought: I need to find Alice's employee ID first and then use it to get her salary.\\nAction: get_employee_id\\nAction Input: Alice\"),\n",
       "   '12345'),\n",
       "  (AgentAction(tool='get_employee_salary', tool_input='Alice', log=\"Thought: Now that I have Alice's employee ID, I can get her salary.\\nAction: get_employee_salary\\nAction Input: Alice\"),\n",
       "   '$100,000')]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# invoke the agent\n",
    "agent_executor.invoke({\n",
    "    \"input\": \"what's the salary of Alice?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ea4910",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aa_agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
